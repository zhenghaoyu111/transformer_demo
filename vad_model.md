# 经过测试 其中Silero VAD效果最好，并且支持多种语言



## VAD 模型分类整理

### 1️⃣ 纯 VAD 模型（专门做 VAD）
这些模型专注于检测音频中的语音活动，只输出“语音/静音”标记。

| 模型名称              | 框架/来源            | 特点                                     |
| ----------------- | ---------------- | -------------------------------------- |
| **WebRTC VAD**    | C/C++ (Python封装) | 经典的基于能量+零交叉检测算法，速度快，超低延迟               |
| **Silero-VAD**    | PyTorch          | 基于轻量神经网络，支持长语音流式检测，开源                  |
| **FSMN-VAD**      | FunASR           | 深度神经网络 FSMN 结构，支持小样本训练                 |
| **MarbleNet VAD** | NVIDIA NeMo      | 专门设计的语音活动检测 CNN 网络                     |
| **TEN-VAD**       | 开源               | Transformer Encoder + Noise 抑制结构，支持端到端 |
| **Torch-VAD**     | PyTorch          | 简单轻量，适合边缘设备                            |

✅ **适用场景**：
- 电话语音检测
- ASR 前端静音过滤
- 低功耗设备实时检测


## 2️⃣ 内置 VAD 的 ASR 模型（语音识别模型内带 VAD）
部分语音识别模型内部集成了 VAD 功能，自动检测语音起止，无需单独 VAD。

| 模型名称                    | 框架/来源          | VAD 功能描述                        |
|-----------------------------|---------------------|---------------------------------------|
| **Whisper (OpenAI)**        | PyTorch             | 内部有段落检测，能区分静音区域         |
| **FunASR (Paraformer)**     | FunASR              | 内置流式 VAD，长音频无需预剪切         |
| **Wav2Vec2.0 + VAD**        | Fairseq / Huggingface | 可配置前置 VAD 层进行预处理         |
| **NeMo ASR (QuartzNet)**    | NVIDIA NeMo         | 流式推理 API 集成了简单 VAD 逻辑       |

✅ **适用场景**：
- 连续识别（会议/客服系统）
- 简化前后处理流程


### 3️⃣非专门 VAD，但可做 VAD 的模型（如 CTC 输出）
这类模型不是专门做 VAD，但通过概率分布或中间输出判断静音区段。

| 技术/模型                   | 说明                                       |
|-----------------------------|----------------------------------------------|
| **CTC-based ASR 模型**      | CTC blank 符号可用作静音检测                 |
| **Attention-based ASR**     | Attention 权重低的区域可能对应静音           |
| **Encoder 输出能量阈值法**  | 统计编码器层输出能量，低于阈值判为静音        |
| **HMM-GMM 声学模型**        | 经典 GMM VAD 可嵌入 HMM 解码中                |

✅ **适用场景**：
- 语音识别后端自动剪切静音
- 流式 ASR 输出流中判断语音段

### 总结：

| 类别               | 优点                | 缺点         |
| ---------------- | ----------------- | ---------- |
| **纯 VAD 模型**     | 专注检测、轻量、低延迟       | 不能识别语音内容   |
| **内置 VAD 的 ASR** | 无需单独调用、识别+VAD 一体化 | 难以单独调优 VAD |
| **CTC 等 VAD替代**  | 不用改网络结构、附加代价低     | 静音检测精度有限   |
 
 

| 模型名称              | 开发方                 | 主要特性                                                                                                                                  | 性能表现                                                                          | 部署方式                                                                                                                         | 许可协议            | 适用场景                                       |
| ----------------- | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------- | ------------------------------------------ |
| **Silero VAD**    | Silero Team         | - 支持 8kHz/16kHz<br>- 支持 PyTorch 和 ONNX<br>- 轻量级（\~2MB）<br>- 多语言支持（6000+）                                                              | - 在 AliMeeting、Earnings21、AISHELL-4 等多个数据集上表现优异<br>- 在 ESC-50 噪声数据集上准确率达 0.61 | - 支持 CPU 和 GPU<br>- 可在浏览器中运行（通过 ONNX）                                                                                        | MIT 许可          | - 呼叫中心<br>- 嵌入式设备<br>- 浏览器端应用              |
| **FSMN-VAD**      | FunASR / ModelScope | - 基于 FSMN 架构<br>- 支持流式和离线模式<br>- 模型小巧（\~1.6MB）<br>- 训练于中文语料，具备抗噪能力                                                                    | - 在 Mac M1 Pro 上处理 70 秒音频仅需 0.6 秒<br>- 实时因子（RTF）可达 0.0077                     | - 支持 ONNX Runtime<br>- 可在 macOS 上运行                                                                                          | MIT 许可          | - 中文语音处理<br>- 嵌入式系统<br>- 实时语音识别            |
| **WebRTC VAD**    | Google              | - 基于传统信号处理<br>- 支持 8kHz、16kHz、32kHz、48kHz 采样率<br>- 低延迟，适用于实时通信                                                                        | - 在多种数据集上表现稳定<br>- 但在噪声环境下性能有限                                                | - C/C++ 实现<br>- 可通过 Python 接口使用（如 py-webrtcvad）                                                                              | BSD 许可          | - 实时通信（VoIP）<br>- 嵌入式系统                    |
| **Cobra VAD**(闭源) | Picovoice           | - 基于深度学习<br>- 提供多平台 SDK（Python、Node.js、Android、iOS 等）<br>- 支持本地运行，保护用户隐私                                                              | - 准确率是 WebRTC VAD 的两倍<br>- 对背景噪声具有较强的鲁棒性                                      | - 跨平台支持<br>- 可嵌入移动设备和浏览器                                                                                                     | 商业许可（需联系销售）     | - 企业级应用<br>- 隐私敏感场景<br>- 移动和嵌入式设备          |
| **MarbleNet VAD** | NVIDIA              | - 基于 CNN 的轻量级模型（91.5K 参数）<br>- 多语言支持（中、英、法、德、俄、西）<br>- 每 20ms 输出一次语音概率                                                                | - 训练时加入了白噪声和真实世界噪声扰动<br>- 在多种语言和噪声环境下表现良好                                     | - 支持 PyTorch 和 ONNX<br>- 可在多种平台部署                                                                                            | NVIDIA 开源模型许可协议 | - 多语言语音识别<br>- 嵌入式系统<br>- 噪声环境下的语音检测       |
| **TEN‑VAD**       | TEN‑framework       | - - 基于深度学习，专为企业级对话系统设计，具备高精度的帧级语音检测能力 <br>    - 检测延迟极低，远优于 WebRTC 和 Silero VAD，快速捕捉语音 → 非语音切换<br>    - 极轻量，库体积小（几十 KB 到几百 KB）、计算资源占用低 | - 与 Silero VAD 比延迟降低 ~32%；      <br>- 能检测动静切换几乎“零延迟”；<br>- 高噪声条件下准确率和误警率表现良好  | - - 提供跨平台支持：C 语言库覆盖 Linux/macOS/Windows/Android/iOS，同时提供 Python 绑定（Linux）及 WebAssembly（WASM）版本 <br>    - 支持 ONNX，便于嵌入各类引擎和设备 | Apache开源许可证     | -适合对延迟敏感的实时对话系统，如智能客服、语音助手、会议记录等，跨平台部署能力强。 |

评价vad模型的指标：
# 📊 VAD 模型性能指标汇总

 1. 精确率 (Precision)
- **中文解释**: 检测为语音的帧中，实际是语音的比例（降低误报）。
- **公式**:  
  <span style="display: inline-block;">\( Precision = \frac{TP}{TP + FP} \)</span>
  - **TP**: 真阳性（语音检测正确）  
  - **FP**: 假阳性（非语音误检为语音）

---

2. 召回率 (Recall) / 灵敏度 (Sensitivity)
- **中文解释**: 实际语音帧中，被检测出来的比例（降低漏报）。
- **公式**:  
  <span style="display: inline-block;">\( Recall = \frac{TP}{TP + FN} \)</span>
  - **FN**: 假阴性（语音漏检）
  - **TN (真阴性)**：指实际为负类，模型也正确预测为负类的样本数。

---

 3. F1 分数 (F1 Score)
- **中文解释**: 精确率和召回率的调和平均，用于平衡二者。
- **公式**:  
 <span style="display: inline-block;">\( F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} \)</span>



> 📝 **说明**:  
- VAD（语音活动检测）模型的目标是 **最大化 F1 和 AUC，最小化 FAR 和 MR**。  
- 在实际应用中，**不同场景可能权衡 Precision 和 Recall**。

# 📂 常用 VAD 数据集

 1. TIMIT
- **中文名称**: TIMIT 语料库
- **简介**: 一个包含 630 名说话人的英文语音数据集，涵盖 8 个主要方言区域。
- **特点**:  
  - 精确的逐帧语音标注  
  - 常用于 VAD 和语音识别的基准测试  
- **链接**: [TIMIT 官方](https://catalog.ldc.upenn.edu/LDC93S1)

---

2. AMI Meeting Corpus
- **中文名称**: AMI 会议语料库
- **简介**: 包含真实会议场景的多通道音频数据，适合测试嘈杂环境下的 VAD 性能。
- **特点**:  
  - 包含多人交谈、背景噪声等复杂场景  
  - 适合鲁棒性 VAD 研究  
- **链接**: [AMI Corpus](http://groups.inf.ed.ac.uk/ami/corpus/)

---

3. CHiME
- **中文名称**: CHiME 挑战数据集
- **简介**: 专为噪声鲁棒性语音处理设计，包含各种噪声环境（街道、家居、公交等）。
- **特点**:  
  - 提供多通道录音  
  - 常用于嘈杂环境 VAD 研究  
- **链接**: [CHiME Challenge](https://chimechallenge.github.io/)

---

4. LibriSpeech
- **中文名称**: LibriSpeech 语料库
- **简介**: 从 LibriVox 有声书提取的英语语音数据集。
- **特点**:  
  - 大规模、高质量、公开  
  - 通常用于训练 VAD 模型  
- **链接**: [LibriSpeech](http://www.openslr.org/12/)

---

5. Aurora-2
- **中文名称**: Aurora-2 数据集
- **简介**: 包含数字串语音数据，并加入了多种噪声环境。
- **特点**:  
  - 含有背景噪声（如街道、列车、机场等）  
  - 适合小词汇表 VAD 测试  
- **链接**: [Aurora Project](https://www.elda.org/)

---

6. QUT-NOISE-TIMIT
- **中文名称**: QUT-TIMIT 噪声数据集
- **简介**: 将 TIMIT 数据与多种真实录制的噪声混合，适合评估嘈杂环境 VAD。
- **特点**:  
  - 真实噪声环境  
  - 逐帧标注  
- **链接**: [QUT-NOISE](https://research.qut.edu.au/saivt/databases/qut-noise-timit/)

---

 7. VoxCeleb
- **中文名称**: VoxCeleb 语音数据集
- **简介**: 大规模说话人验证和识别数据集，可用于 VAD 模型预训练。
- **特点**:  
  - 多语言、多说话人  
  - 包含多种噪声和设备差异  
- **链接**: [VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/)




下面是我自己实际测试得到的数据：
使用的是公开标注的数据集：https://github.com/jtkim-kaist/VAD?tab=readme-ov-file
其中中文数据集：https://modelscope.cn/datasets/speech_tts/AISHELL-3/summary?utm_source=chatgpt.com
运行环境：macos M4

| vad model     | TP    | FP    | FN    | TN    | Precision | Recall | F1     | 延迟     |
| ------------- | ----- | ----- | ----- | ----- | --------- | ------ | ------ | ------ |
| Silero‑VAD v4 | 14687 | 1221  | 571   | 39897 | 0.9232    | 0.9626 | 0.9425 | 4.97s  |
| FSMN-VAD      | 448   | 681   | 14810 | 40437 | 0.3968    | 0.0294 | 0.0547 | 5.47s  |
| WebRTC VAD    | 12871 | 11443 | 3407  | 32413 | 0.5294    | 0.7907 | 0.6342 | 0.168s |
| MarbleNet VAD | 27    | 11    | 690   | 175   | 0.7105    | 0.0377 | 0.0715 | 7.45s  |
| TEN-VAD       | 14047 | 40993 | 1177  | 118   | 0.2552    | 0.9227 | 0.3998 | 2.44s  |

这是Silero‑VAD v4  测试的结果
![](./image-1.png)

FSMN-VAD：（因为这个模型是对中文比较友好，使用的数据集是没有中文内容，所以效果比较差）
![](./image-2.png)
WebRTC:
![](./image-3.png)
MarbleNet VAD（默认是用于短音频）：
![](./image-4.png)
TEN-VAD:
![](./image-5.png)

总结

| **排名**   | **模型**                                  | **优势**                                 | **劣势**        |
| -------- | --------------------------------------- | -------------------------------------- | ------------- |
| 🥇 **1** | **Silero‑VAD**                          | **Precision, Recall, F1 全面领先**，误报少，漏检少 | 延迟比 WebRTC 略高 |
| 🥈 **2** | **WebRTC VAD**                          | 延迟极低，简单快速，适合实时应用                       | 精度一般，误报较多     |
| 🥉 **3** | TEN-VAD                                 | 召回率高（漏检少），适合希望不漏任何语音的场景                | 精度差，误报非常多     |
|          | FSMN-VAD（使用的数据集不是中文，中文数据集效果好，其他数据集效果很差） | **性能全面崩盘**（几乎漏检所有语音）                   | 精度低、召回率低      |
| 🚫       | MarbleNet VAD                           | 准确性极低，几乎检测不到语音                         | 推理时间还特别长      |


[^1]: 
