# 经过测试 其中Silero VAD效果最好，并且支持多种语言



## VAD 模型分类整理

### 1️⃣ 纯 VAD 模型（专门做 VAD）
这些模型专注于检测音频中的语音活动，只输出“语音/静音”标记。

| 模型名称              | 框架/来源            | 特点                                     |
| ----------------- | ---------------- | -------------------------------------- |
| **WebRTC VAD**    | C/C++ (Python封装) | 经典的基于能量+零交叉检测算法，速度快，超低延迟               |
| **Silero-VAD**    | PyTorch          | 基于轻量神经网络，支持长语音流式检测，开源                  |
| **FSMN-VAD**      | FunASR           | 深度神经网络 FSMN 结构，支持小样本训练                 |
| **MarbleNet VAD** | NVIDIA NeMo      | 专门设计的语音活动检测 CNN 网络                     |
| **TEN-VAD**       | 开源               | Transformer Encoder + Noise 抑制结构，支持端到端 |
| **Torch-VAD**     | PyTorch          | 简单轻量，适合边缘设备                            |

✅ **适用场景**：
- 电话语音检测
- ASR 前端静音过滤
- 低功耗设备实时检测


## 2️⃣ 内置 VAD 的 ASR 模型（语音识别模型内带 VAD）
部分语音识别模型内部集成了 VAD 功能，自动检测语音起止，无需单独 VAD。

| 模型名称                    | 框架/来源          | VAD 功能描述                        |
|-----------------------------|---------------------|---------------------------------------|
| **Whisper (OpenAI)**        | PyTorch             | 内部有段落检测，能区分静音区域         |
| **FunASR (Paraformer)**     | FunASR              | 内置流式 VAD，长音频无需预剪切         |
| **Wav2Vec2.0 + VAD**        | Fairseq / Huggingface | 可配置前置 VAD 层进行预处理         |
| **NeMo ASR (QuartzNet)**    | NVIDIA NeMo         | 流式推理 API 集成了简单 VAD 逻辑       |

✅ **适用场景**：
- 连续识别（会议/客服系统）
- 简化前后处理流程


### 3️⃣非专门 VAD，但可做 VAD 的模型（如 CTC 输出）
这类模型不是专门做 VAD，但通过概率分布或中间输出判断静音区段。

| 技术/模型                   | 说明                                       |
|-----------------------------|----------------------------------------------|
| **CTC-based ASR 模型**      | CTC blank 符号可用作静音检测                 |
| **Attention-based ASR**     | Attention 权重低的区域可能对应静音           |
| **Encoder 输出能量阈值法**  | 统计编码器层输出能量，低于阈值判为静音        |
| **HMM-GMM 声学模型**        | 经典 GMM VAD 可嵌入 HMM 解码中                |

✅ **适用场景**：
- 语音识别后端自动剪切静音
- 流式 ASR 输出流中判断语音段

### 总结：

| 类别               | 优点                | 缺点         |
| ---------------- | ----------------- | ---------- |
| **纯 VAD 模型**     | 专注检测、轻量、低延迟       | 不能识别语音内容   |
| **内置 VAD 的 ASR** | 无需单独调用、识别+VAD 一体化 | 难以单独调优 VAD |
| **CTC 等 VAD替代**  | 不用改网络结构、附加代价低     | 静音检测精度有限   |

## 主要流行的纯VAD模型

| 模型名称              | 开发方                 | 主要特性                                                                                                                                  | 性能表现                                                                          | 部署方式                                                                                                                         | 许可协议            | 适用场景                                       |
| ----------------- | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------- | ------------------------------------------ |
| **Silero VAD**    | Silero Team         | - 支持 8kHz/16kHz<br>- 支持 PyTorch 和 ONNX<br>- 轻量级（\~2MB）<br>- 多语言支持（6000+）                                                              | - 在 AliMeeting、Earnings21、AISHELL-4 等多个数据集上表现优异<br>- 在 ESC-50 噪声数据集上准确率达 0.61 | - 支持 CPU 和 GPU<br>- 可在浏览器中运行（通过 ONNX）                                                                                        | MIT 许可          | - 呼叫中心<br>- 嵌入式设备<br>- 浏览器端应用              |
| **FSMN-VAD**      | FunASR / ModelScope | - 基于 FSMN 架构<br>- 支持流式和离线模式<br>- 模型小巧（\~1.6MB）<br>- 训练于中文语料，具备抗噪能力                                                                    | - 在 Mac M1 Pro 上处理 70 秒音频仅需 0.6 秒<br>- 实时因子（RTF）可达 0.0077                     | - 支持 ONNX Runtime<br>- 可在 macOS 上运行                                                                                          | MIT 许可          | - 中文语音处理<br>- 嵌入式系统<br>- 实时语音识别            |
| **WebRTC VAD**    | Google              | - 基于传统信号处理<br>- 支持 8kHz、16kHz、32kHz、48kHz 采样率<br>- 低延迟，适用于实时通信                                                                        | - 在多种数据集上表现稳定<br>- 但在噪声环境下性能有限                                                | - C/C++ 实现<br>- 可通过 Python 接口使用（如 py-webrtcvad）                                                                              | BSD 许可          | - 实时通信（VoIP）<br>- 嵌入式系统                    |
| **Cobra VAD**(闭源) | Picovoice           | - 基于深度学习<br>- 提供多平台 SDK（Python、Node.js、Android、iOS 等）<br>- 支持本地运行，保护用户隐私                                                              | - 准确率是 WebRTC VAD 的两倍<br>- 对背景噪声具有较强的鲁棒性                                      | - 跨平台支持<br>- 可嵌入移动设备和浏览器                                                                                                     | 商业许可（需联系销售）     | - 企业级应用<br>- 隐私敏感场景<br>- 移动和嵌入式设备          |
| **MarbleNet VAD** | NVIDIA              | - 基于 CNN 的轻量级模型（91.5K 参数）<br>- 多语言支持（中、英、法、德、俄、西）<br>- 每 20ms 输出一次语音概率                                                                | - 训练时加入了白噪声和真实世界噪声扰动<br>- 在多种语言和噪声环境下表现良好                                     | - 支持 PyTorch 和 ONNX<br>- 可在多种平台部署                                                                                            | NVIDIA 开源模型许可协议 | - 多语言语音识别<br>- 嵌入式系统<br>- 噪声环境下的语音检测       |
| **TEN‑VAD**       | TEN‑framework       | - - 基于深度学习，专为企业级对话系统设计，具备高精度的帧级语音检测能力 <br>    - 检测延迟极低，远优于 WebRTC 和 Silero VAD，快速捕捉语音 → 非语音切换<br>    - 极轻量，库体积小（几十 KB 到几百 KB）、计算资源占用低 | - 与 Silero VAD 比延迟降低 ~32%；      <br>- 能检测动静切换几乎“零延迟”；<br>- 高噪声条件下准确率和误警率表现良好  | - - 提供跨平台支持：C 语言库覆盖 Linux/macOS/Windows/Android/iOS，同时提供 Python 绑定（Linux）及 WebAssembly（WASM）版本 <br>    - 支持 ONNX，便于嵌入各类引擎和设备 | Apache开源许可证     | -适合对延迟敏感的实时对话系统，如智能客服、语音助手、会议记录等，跨平台部署能力强。 |


### VAD 模型性能指标汇总

 1. 精确率 (Precision)
- **中文解释**: 检测为语音的帧中，实际是语音的比例（降低误报）。
- **公式**:  
   `Precision = TP / (TP + FP)`
  - **TP**: 真阳性（语音检测正确）  
  - **FP**: 假阳性（非语音误检为语音）

---

2. 召回率 (Recall) / 灵敏度 (Sensitivity)
- **中文解释**: 实际语音帧中，被检测出来的比例（降低漏报）。
- **公式**:  
  `Recall = TP / (TP + FN)`
  - **FN**: 假阴性（语音漏检）
  - **TN (真阴性)**：指实际为负类，模型也正确预测为负类的样本数。

---

 3. F1 分数 (F1 Score)
- **中文解释**: 精确率和召回率的调和平均，用于平衡二者。
- **公式**:  
   `F1 = 2 * (Precision * Recall) / (Precision + Recall)`



> 📝 **说明**:  
- VAD（语音活动检测）模型的目标是 **最大化 F1 。  
- 在实际应用中，**不同场景可能权衡 Precision 和 Recall**。

### 常用 VAD 数据集

1. AISHELL-3
- **中文名称**: AISHELL-3 中文语音数据集
- **简介**: 大规模多说话人中文语音合成数据集，可用于 VAD、TTS 及 ASR 任务的预训练。
- **特点**:
    - 覆盖 218 名不同性别、口音的中文说话人
    - 约 85 小时高质量录音
    - 适合语音合成、说话人建模等应用
- **链接**: [AISHELL-3](https://modelscope.cn/datasets/speech_tts/AISHELL-3/summary?utm_source=chatgpt.com)

2. LibriSpeech
- **中文名称**: LibriSpeech 语音数据集
- **简介**: 一个基于英语有声书的大规模语音识别数据集，广泛应用于语音识别 (ASR) 和 VAD 任务。
- **特点**:
    - 大量英语语音，采样率为 16kHz
    - 包含训练、验证、测试子集
    - 高质量朗读录音，文本标注完备
- **链接**: [LibriSpeech](http://www.openslr.org/12/)

1. VoxCeleb
- **中文名称**: VoxCeleb 语音数据集
- **简介**: 大规模说话人验证和识别数据集，可用于 VAD 模型预训练。
- **特点**:
    - 多语言、多说话人
    - 包含多种噪声和设备差异
- **链接**: [VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/)


下面是我自己实际测试得到的数据：
使用的是公开标注的数据集：https://github.com/jtkim-kaist/VAD?tab=readme-ov-file
其中中文数据集：https://modelscope.cn/datasets/speech_tts/AISHELL-3/summary?utm_source=chatgpt.com
运行环境：macos M4

| vad model     | TP    | FP    | FN    | TN    | Precision | Recall | F1     | 延迟     |
| ------------- | ----- | ----- | ----- | ----- | --------- | ------ | ------ | ------ |
| Silero‑VAD v4 | 14687 | 1221  | 571   | 39897 | 0.9232    | 0.9626 | 0.9425 | 4.97s  |
| FSMN-VAD      | 448   | 681   | 14810 | 40437 | 0.3968    | 0.0294 | 0.0547 | 5.47s  |
| WebRTC VAD    | 12871 | 11443 | 3407  | 32413 | 0.5294    | 0.7907 | 0.6342 | 0.168s |
| MarbleNet VAD | 27    | 11    | 690   | 175   | 0.7105    | 0.0377 | 0.0715 | 7.45s  |
| TEN-VAD       | 14047 | 40993 | 1177  | 118   | 0.2552    | 0.9227 | 0.3998 | 2.44s  |
### 模型加速问题
模型均使用cpu进行测试，因为mac不支持CUDA。如果使用mps的GPU加速小型的模型会造成传输数据时间长，反而导致整个程序运行时间比在cpu上运行时间长。

## 总结

| **排名**   | **模型**                                  | **优势**                                 | **劣势**        |
| -------- | --------------------------------------- | -------------------------------------- | ------------- |
| 🥇 **1** | **Silero‑VAD**                          | **Precision, Recall, F1 全面领先**，误报少，漏检少 | 延迟比 WebRTC 略高 |
| 🥈 **2** | **WebRTC VAD**                          | 延迟极低，简单快速，适合实时应用                       | 精度一般，误报较多     |
| 🥉 **3** | TEN-VAD                                 | 召回率高（漏检少），适合希望不漏任何语音的场景                | 精度差，误报非常多     |
|          | FSMN-VAD（使用的数据集不是中文，中文数据集效果好，其他数据集效果很差） | **性能全面崩盘**（几乎漏检所有语音）                   | 精度低、召回率低      |
| 🚫       | MarbleNet VAD                           | 准确性极低，几乎检测不到语音                         | 推理时间还特别长      |

